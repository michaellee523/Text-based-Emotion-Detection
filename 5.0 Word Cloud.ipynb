{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "import jsonpickle\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data into data frame\n",
    "#Change here if you want to view other dataset\n",
    "data = pd.read_csv('Resources/testing_dataset_labelled.csv',header = 0)\n",
    "\n",
    "\n",
    "#Clean the missing data\n",
    "count = 0\n",
    "for line in data.content:\n",
    "    if line in ['0', nan]:\n",
    "        data = data.drop(data.index[count])\n",
    "        count = count - 1\n",
    "    count = count + 1\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# print(tabulate(data.head(10), showindex=True, headers=data.columns))\n",
    "\n",
    "outputs = open('Outputs/pkl/testing_dataset_labelled.pkl','wb')\n",
    "pickle.dump(data, outputs)\n",
    "outputs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "pkl_file = open('outputs/pkl/testing_dataset_labelled.pkl', 'rb')\n",
    "data = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "neutral = []\n",
    "surprise = []\n",
    "empty = []\n",
    "happiness = []\n",
    "love = []\n",
    "fun = []\n",
    "relief = []\n",
    "enthusiasm = []\n",
    "worry = []\n",
    "sadness = []\n",
    "hate = []\n",
    "boredom = []\n",
    "anger = []\n",
    "allemotion = [neutral, surprise, empty, happiness, love, fun, relief, enthusiasm, worry, sadness, hate, boredom, anger]\n",
    "nameofemotion = ['neutral', 'surprise', 'empty', 'happiness', 'love', 'fun', 'relief', 'enthusiasm', 'worry', 'sadness', 'hate', 'boredom', 'anger']\n",
    "\n",
    "for num in range(len(data)):\n",
    "    if(data.sentiment[num] == 'neutral'):\n",
    "        neutral.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'surprise'):\n",
    "        surprise.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'empty'):\n",
    "        empty.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'happiness'):\n",
    "        happiness.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'love'):\n",
    "        love.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'fun'):\n",
    "        fun.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'relief'):\n",
    "        relief.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'enthusiasm'):\n",
    "        enthusiasm.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'worry'):\n",
    "        worry.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'sadness'):\n",
    "        sadness.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'hate'):\n",
    "        hate.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'boredom'):\n",
    "        boredom.append(data.content[num])\n",
    "\n",
    "    elif(data.sentiment[num] == 'anger'):\n",
    "        anger.append(data.content[num])\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "for emotion in allemotion:\n",
    "    allwords = [] #Clear everytime to store different emotion sentences\n",
    "    fdist = []\n",
    "    for line in emotion:\n",
    "        #If you want to use for preprocessed data of 1,2,3,4 and 5, then uncomment below\n",
    "        #Preprocessing\n",
    "        #####################################################\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"http\\S+\", \"\", line)\n",
    "        line = re.sub(r\"&amp\", \"\", line)\n",
    "        line = re.sub(r\"rt\", \"\", line)\n",
    "        line = re.sub(r\"n't\", \"\", line)\n",
    "        line = re.sub(r\"'s\", \"\", line)\n",
    "        line = word_tokenize(str(line))\n",
    "        line = [re.sub(r'[^A-Za-z0-9]+', '', t) for t in line]\n",
    "        line = filter(None, line)\n",
    "        #####################################################\n",
    "\n",
    "        for word in line:\n",
    "            if word not in stopwords:\n",
    "                allwords.append(word)\n",
    "    fdist = nltk.FreqDist(t for t in allwords)\n",
    "    df = pd.DataFrame(columns=['Word', 'Frequency'])\n",
    "    for word, frequency in fdist.most_common(50):\n",
    "        df = df.append({'Word':word, 'Frequency':frequency}, ignore_index = True)\n",
    "\n",
    "    #Save the file in pickle format\n",
    "    outputs = open('Outputs/pkl/WC/result_testdataset_{}.pkl'.format(nameofemotion[count]),'wb')\n",
    "\n",
    "    pickle.dump(df, outputs)\n",
    "    outputs.close()\n",
    "    wordcloud = WordCloud(    background_color='white',\n",
    "                      width=1200,\n",
    "                      height=1000\n",
    "                     ).generate_from_frequencies(fdist)\n",
    "\n",
    "    wordcloud.to_file(filename='Outputs/graph/WC/result_dataset_{}.png'.format(nameofemotion[count]))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "#         plt.show()\n",
    "    df.drop(df.index, inplace=True)\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
