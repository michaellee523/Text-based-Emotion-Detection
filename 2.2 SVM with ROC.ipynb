{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pickle\n",
    "import string\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load : File  3\n",
      "Transform : File  3\n",
      "Training : File  3\n",
      "Save : File  3\n",
      "File  3  is completed.\n",
      "\n",
      "Minute : 161.1684769709905\n",
      "Hour : 2.6861412828498414\n"
     ]
    }
   ],
   "source": [
    "full_program_time_1 = time.time()\n",
    "for num in range(3, 4):\n",
    "    \n",
    "    #Load the file from pickle\n",
    "    print('Load : File ', num)\n",
    "    \n",
    "    #Read the train data\n",
    "    pkl_file = open('outputs/pkl/preprocessed_data_%s.pkl'%num, 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    \n",
    "    #Read the test data which is real data\n",
    "    pkl_file = open('outputs/pkl/preprocessed_test_data_1.pkl', 'rb')\n",
    "    testdata = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "\n",
    "    if num >= 6:\n",
    "        \n",
    "        #Untokenize the data\n",
    "        print('Untokenize : File ', num)\n",
    "        \n",
    "        count = 0\n",
    "        for line in data.content:\n",
    "            data.content[count] = \"\".join([\" \"+ a if not a.startswith(\"'\") and a not in string.punctuation else a for a in line]).strip()\n",
    "            count = count + 1\n",
    "    \n",
    "    X_train = data.content\n",
    "    y_train = data.sentiment\n",
    "    \n",
    "    \n",
    "    X_test = testdata.content\n",
    "    y_test = testdata.sentiment\n",
    "    \n",
    "    \n",
    "    # Binarize the output\n",
    "    y_train = label_binarize(y_train, classes=['neutral', 'surprise', 'empty', 'happiness', 'love', 'fun', 'relief', 'enthusiasm', 'worry', 'sadness', 'hate', 'boredom', 'anger'])\n",
    "    y_test = label_binarize(y_test, classes=['neutral', 'surprise', 'empty', 'happiness', 'love', 'fun', 'relief', 'enthusiasm', 'worry', 'sadness', 'hate', 'boredom', 'anger'])\n",
    "    n_classes = y_train.shape[1]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                                max_df = 0.8,\n",
    "                                sublinear_tf = True,\n",
    "                                use_idf = True)\n",
    "\n",
    "    \n",
    "#     #Split the data into 7:3 ratio\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state = 123)\n",
    "\n",
    "    \n",
    "    #Transform the words to feature vectors\n",
    "    \n",
    "    print('Transform : File ', num)\n",
    "    \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    \n",
    "    ########## SVM ##########\n",
    "    \n",
    "    print('Training : File ', num)\n",
    "    \n",
    "    classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))\n",
    "    \n",
    "    y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "    \n",
    "    ########## SVM ##########\n",
    "    \n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    \n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    \n",
    "    \n",
    "    lw = 2\n",
    "    fig = plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    colors = cycle(['greenyellow', 'limegreen', 'lime', 'darkblue', 'slateblue', 'dodgerblue', 'skyblue', 'cadetblue', 'firebrick', 'red', 'darksalmon', 'sienna', 'sandybrown'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "    \n",
    "\n",
    "    plt.plot([0,1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "    lgd = plt.legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
    "    \n",
    "    \n",
    "    print('Save : File ', num)\n",
    "    \n",
    "    result = [['svm_linear_result', y_score, time_1, time_2]]\n",
    "        \n",
    "    df = pd.DataFrame(result, columns=['Type of kernel (SVM)','Y Score', 'Time_1', 'Time_2'])    \n",
    "    \n",
    "    #Persist the model & Vectorizer\n",
    "    joblib.dump(classifier, 'Backup/SVM/2.2_svm_model_roc_%s_3.pkl'%num)\n",
    "    joblib.dump(vectorizer, 'Backup/SVM/2.2_svm_model_roc_%s_vectorizer_3.pkl'%num)\n",
    "    \n",
    "    fig.savefig('outputs/graph/SVM/roc_preprocessed_data_result_%s_3.png'%num, bbox_extra_artists = (lgd,), bbox_inches = 'tight')\n",
    "    \n",
    "    outputs = open('Outputs/pkl/SVM/2.2_svm_roc_%s_result_3.pkl'%num,'wb')\n",
    "    pickle.dump(df, outputs)\n",
    "    outputs.close()\n",
    "    \n",
    "    print('File ' ,num , ' is completed.\\n')\n",
    "\n",
    "    \n",
    "full_program_time_2 = time.time()\n",
    "second = full_program_time_2 - full_program_time_1\n",
    "minute = second/60\n",
    "hour = minute/60\n",
    "print('Minute :', minute)\n",
    "print('Hour :', hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
